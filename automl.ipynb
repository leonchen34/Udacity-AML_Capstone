{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1690677098223
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.run import Run\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "\"Airbnb for Boston with fraud detcetion\" data was downloaded from Kaggle with the following link:\n",
    "\n",
    "https://www.kaggle.com/datasets/hawkingcr/airbnb-for-boston-with-fraud-detection/download?datasetVersionNumber=1\n",
    "\n",
    "The downloaded file was saved as \"output.csv\" in the \"data\" directory. The dataset aims to classify whether an Airbnb listing is a fraud or not.\n",
    "\n",
    "A notebook file named \"data_process.ipyng\" was created to perform some pre-processing on the data. Firstly, a correlation analysis was conducted with the target column \"fraud\" to identify and remove some non-significant features. Next, the data was split into \"train.csv\" and \"test.csv\" sets, and the balance of the training data was examined. Due to the class imbalance in the training target, an upsampling technique was applied to address this imbalance\n",
    "\n",
    "### Create Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1690677128832
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from scripts.data_set import getTrainingDataset\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "experiment_name = 'udacity-aml-capstone-automl'\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "\n",
    "train_ds = getTrainingDataset(ws)\n",
    "train_ds.to_pandas_dataframe().head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Attach an AmlCompute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690677154314
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "cluster_name = \"my-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print(\"Found existing cluster, use it.\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"STANDARD_D2_V2\", max_nodes=4\n",
    "    )\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "compute_target.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "iteration_timeout_minutes: Time limit in minutes for each iteration. Increase this value for larger datasets that need more time for each iteration. Here it is set to 10 minutes for the relative small dataset.\n",
    "\n",
    "experiment_timeout_hours: Maximum amount of time that all iterations combined can take before the experiment terminates. Here it is set tp 30 minutes for the relative small dataset.\n",
    "\n",
    "enable_early_stopping: Flag to enable early termination if the score is not improving in the short term.\n",
    "\n",
    "primary_metric: Since the data is very imbalanced, \"AUC_weighted\" is chosen here.\n",
    "\n",
    "featurization: By using auto, the experiment can preprocess the input data (handling missing data, converting text to numeric, etc.)\n",
    "\n",
    "verbosity: Controls the level of logging.\n",
    "\n",
    "n_cross_validation: Number of cross validation to perform since validation data is not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1690677163576
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\": 10,\n",
    "    \"experiment_timeout_minutes\": 30,\n",
    "    \"max_concurrent_iterations\": 4,\n",
    "    \"enable_early_stopping\": True,\n",
    "    \"primary_metric\": 'AUC_weighted',\n",
    "    \"featurization\": 'auto',\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"n_cross_validations\": 5\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(\n",
    "    task=\"classification\",\n",
    "    compute_target=compute_target,\n",
    "    training_data=train_ds,\n",
    "    label_column_name=\"fraud\",\n",
    "    enable_onnx_compatible_models=True,\n",
    "    **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1690677183736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit experiment\n",
    "auto_run = experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1690677245002
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(auto_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1690678820198
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve best automl model.\n",
    "\n",
    "auto_run.wait_for_completion(show_output=True)\n",
    "assert(auto_run.get_status() == \"Completed\")\n",
    "\n",
    "best_auto_run, best_model = auto_run.get_output()\n",
    "# best_auto_child = auto_run.get_best_child()\n",
    "\n",
    "# Save the best model\n",
    "\n",
    "output_dir = \"./outputs\"\n",
    "if os.path.exists(output_dir) == False:\n",
    "    os.mkdir(output_dir)\n",
    "best_model_file = output_dir + \"/best_model.pkl\"\n",
    "joblib.dump(best_model,best_model_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print run properties\n",
    "\n",
    "print(best_auto_run.get_file_names())\n",
    "run_env = auto_run.get_environment()\n",
    "print (run_env)\n",
    "best_auto_run_env = best_auto_run.get_environment()\n",
    "print(best_auto_run_env)\n",
    "# print(best_auto_run.get_details())\n",
    "print(best_auto_run.get_properties())\n",
    "\n",
    "#env_file = output_dir + \"/env_file\"\n",
    "# if json, serializing first\n",
    "# json_object = json.dumps(best_auto_run_env, indent=4)\n",
    "#with open(env_file,\"w\") as f\n",
    "    #f.write(best_auto_run_env)\n",
    "    #f.write(json_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print best model properties\n",
    "\n",
    "print(best_model.get_model_path())\n",
    "print(best_model.get_sas_urls())\n",
    "print(best_model.print_configuration())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690679826332
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_file = src_dir + \"/test.csv\";\n",
    "df_test = pd.read_csv(test_file)\n",
    "df_test = df_test[pd.notnull(df_test['fraud'])]\n",
    "\n",
    "y_test = df_test['fraud']\n",
    "X_test = df_test.drop(['fraud'], axis=1)\n",
    "\n",
    "ypred = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, ypred)\n",
    "pd.DataFrame(cm).style.background_gradient(cmap='Blues', low=0, high=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and save ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
    "\n",
    "bestrun, onnx_mdl = auto_run.get_output(return_onnx_model=True)\n",
    "\n",
    "onnx_fl_path = output_dir+\"/best_model.onnx\"\n",
    "OnnxConverter.save_onnx_model(onnx_mdl, onnx_fl_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with ONNX model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# import json\n",
    "from azureml.automl.core.onnx_convert import OnnxConvertConstants\n",
    "from azureml.train.automl import constants\n",
    "from azureml.automl.runtime.onnx_convert import OnnxInferenceHelper\n",
    "\n",
    "print(constants.MODEL_RESOURCE_PATH_ONNX)\n",
    "\n",
    "def get_onnx_res(run):\n",
    "    res_path = output_dir + \"/onnx_resource.json\"\n",
    "    run.download_file(\n",
    "        name=constants.MODEL_RESOURCE_PATH_ONNX, output_file_path=res_path\n",
    "    )\n",
    "    with open(res_path) as f:\n",
    "        result = json.load(f)\n",
    "    return result\n",
    "\n",
    "\n",
    "if sys.version_info < OnnxConvertConstants.OnnxIncompatiblePythonVersion:\n",
    "    # test_df = test_dataset.to_pandas_dataframe()\n",
    "    mdl_bytes = onnx_mdl.SerializeToString()\n",
    "    onnx_result = get_onnx_res(bestrun)\n",
    "\n",
    "    onnxrt_helper = OnnxInferenceHelper(mdl_bytes, onnx_result)\n",
    "    pred_onnx, pred_prob_onnx = onnxrt_helper.predict(X_test)\n",
    "    #print(pred_onnx)\n",
    "    #print(pred_prob_onnx)\n",
    "else:\n",
    "    print(\"Please use Python version 3.6 or higher to run the inference helper.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, pred_onnx)\n",
    "pd.DataFrame(cm).style.background_gradient(cmap='Blues', low=0, high=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Registration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690679713518
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_name = best_auto_run.properties[\"model_name\"]\n",
    "#print(model_name)\n",
    "description = \"AutoML Model to predict Airbnb fraud listing\"\n",
    "tags = None\n",
    "registered_model = auto_run.register_model(\n",
    "    model_name=model_name, description=description, tags=tags\n",
    ")\n",
    "\n",
    "print(\n",
    "    auto_run.model_id\n",
    ") \n",
    "\n",
    "print(\"registered model: \",registered_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690681280723
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "# download score file\n",
    "\n",
    "script_file_name = output_dir + \"/score.py\"\n",
    "best_auto_run.download_file(\"outputs/scoring_file_v_1_0_0.py\", script_file_name)\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    environment=best_auto_run.get_environment(), entry_script=script_file_name\n",
    ")\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=2,\n",
    "    memory_gb=2,\n",
    "    #tags={\"area\": \"bmData\", \"type\": \"automl_classification\"},\n",
    "    tags={\"type\": \"automl_classification\"},\n",
    "    description=\"Automl Classification Service\",\n",
    ")\n",
    "\n",
    "aci_service_name = model_name.lower()\n",
    "print(aci_service_name)\n",
    "aci_service = Model.deploy(ws, aci_service_name, [registered_model], inference_config, aciconfig)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.scoring_uri)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the logs of the web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690682083586
    }
   },
   "outputs": [],
   "source": [
    "aci_service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Send a request to the web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1690683014092
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import requests\n",
    "\n",
    "X_test_json = X_test.to_json(orient=\"records\")\n",
    "#data = '{\"data\": ' + X_test_json + \"}\"\n",
    "data = '{\"data\": ' + X_test_json + ', \"method\": \"predict\"}'\n",
    "#print(\"test data:\", data)\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "resp = requests.post(aci_service.scoring_uri, data, headers=headers)\n",
    "\n",
    "y_pred = json.loads(json.loads(resp.text))[\"result\"]\n",
    "#print(y_pred)\n",
    "#print(y_test)\n",
    "actual = array(y_test)\n",
    "#actual = actual[:, 0]\n",
    "#print(len(y_pred), \" \", len(actual))\n",
    "#print(actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(actual, ypred)\n",
    "pd.DataFrame(cm).style.background_gradient(cmap='Blues', low=0, high=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service.delete()\n",
    "\n",
    "compute_target.delete()\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
