{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1690677098223
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.run import Run\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import json\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "\"Airbnb for Boston with fraud detcetion\" data was downloaded from Kaggle with the following link:\n",
    "\n",
    "https://www.kaggle.com/datasets/hawkingcr/airbnb-for-boston-with-fraud-detection/download?datasetVersionNumber=1\n",
    "\n",
    "The downloaded file was saved as \"output.csv\" in the \"data\" directory. The dataset aims to classify whether an Airbnb listing is a fraud or not.\n",
    "\n",
    "A notebook file named \"data_process.ipyng\" was created to perform some pre-processing on the data. Firstly, a correlation analysis was conducted with the target column \"fraud\" to identify and remove some non-significant features. Next, the data was split into \"train.csv\" and \"test.csv\" sets, and the balance of the training data was examined. Due to the class imbalance in the training target, an upsampling technique was applied to address this imbalance\n",
    "\n",
    "### Create Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1690677128832
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "experiment_name = 'udacity-aml-capstone'\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "train_data_file = \"train.csv\"\n",
    "src_dir = \"./data\"\n",
    "target_path = \"airbnb_boston\"\n",
    "\n",
    "train_data_dir = \"./tmp_dir\"\n",
    "if os.path.exists(train_data_dir) == False:\n",
    "    os.mkdir(train_data_dir)\n",
    "\n",
    "src_file_path = os.path.join(src_dir,train_data_file)\n",
    "dest = shutil.copy(src_file_path,train_data_dir)\n",
    "#print(os.listdir(train_data_dir))\n",
    "\n",
    "Dataset.File.upload_directory(train_data_dir,(datastore,target_path),\n",
    "                              overwrite=True, show_progress=True)\n",
    "\n",
    "# Upload the training data as a tabular dataset for access during training on remote compute\n",
    "datastore_path = os.path.join(target_path,train_data_file)\n",
    "print(\"datastore train data path: \",datastore_path)\n",
    "train_ds = Dataset.Tabular.from_delimited_files(\n",
    "    path=datastore.path(datastore_path)\n",
    ")\n",
    "\n",
    "train_ds.to_pandas_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Attach an AmlCompute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690677154314
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "cluster_name = \"my-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print(\"Found existing cluster, use it.\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"STANDARD_D2_V2\", max_nodes=4\n",
    "    )\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "compute_target.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "TODO: Explain why you chose the automl settings and cofiguration you used below.\n",
    "\n",
    "iteration_timeout_minutes: Time limit in minutes for each iteration. Increase this value for larger datasets that need more time for each iteration.\n",
    "\n",
    "experiment_timeout_hours: Maximum amount of time in hours that all iterations combined can take before the experiment terminates.\n",
    "\n",
    "enable_early_stopping: Flag to enable early termination if the score is not improving in the short term.\n",
    "\n",
    "primary_metric: Metric that you want to optimize. The best-fit model will be chosen based on this metric.\n",
    "\n",
    "featurization: By using auto, the experiment can preprocess the input data (handling missing data, converting text to numeric, etc.)\n",
    "\n",
    "verbosity: Controls the level of logging.\n",
    "\n",
    "n_cross_validation: Number of cross validation to perform when validation data is\n",
    "                    not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1690677163576
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\": 10,\n",
    "    \"experiment_timeout_minutes\": 30,\n",
    "    \"max_concurrent_iterations\": 4,\n",
    "    \"enable_early_stopping\": True,\n",
    "    \"primary_metric\": 'AUC_weighted',\n",
    "    \"featurization\": 'auto',\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"n_cross_validations\": 5\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(\n",
    "    task=\"classification\",\n",
    "    compute_target=compute_target,\n",
    "    training_data=train_ds,\n",
    "    label_column_name=\"fraud\",\n",
    "    blocked_models=[\"KNN\", \"LinearSVM\"],\n",
    "    enable_onnx_compatible_models=True,\n",
    "    **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1690677183736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit experiment\n",
    "auto_run = experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1690677245002
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(auto_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1690678820198
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve and save best automl model.\n",
    "\n",
    "# import joblib\n",
    "\n",
    "auto_run.wait_for_completion(show_output=True)\n",
    "assert(auto_run.get_status() == \"Completed\")\n",
    "\n",
    "best_auto_run, best_model = auto_run.get_output()\n",
    "# best_auto_child = auto_run.get_best_child()\n",
    "# best_run, onnx_mdl = auto_run.get_output(return_onnx_model=True)\n",
    "\n",
    "# Save the best model\n",
    "output_dir = \"./outputs\"\n",
    "if os.path.exists(output_dir) == False:\n",
    "    os.mkdir(output_dir)\n",
    "best_model_file = output_dir + \"/best_model.pkl\"\n",
    "joblib.dump(best_model,best_model_file)\n",
    "\n",
    "print(best_auto_run.get_environment())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print best model properties\n",
    "\n",
    "print(best_model.get_model_path())\n",
    "print(best_model.get_sas_urls())\n",
    "best_model.print_configuration()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690679125827
    }
   },
   "outputs": [],
   "source": [
    "# download some outputs\n",
    "\n",
    "# import json\n",
    "# import pandas as pd\n",
    "\n",
    "print(best_auto_run.get_file_names())\n",
    "# print(best_auto_run.get_details())\n",
    "print(best_auto_run.get_properties())\n",
    "\n",
    "script_file_name = output_dir + \"/score.py\"\n",
    "best_auto_run.download_file(\"outputs/scoring_file_v_1_0_0.py\", script_file_name)\n",
    "\n",
    "# Download the featurization summary JSON file locally\n",
    "featurization_file_name = output_dir + \"/featurization_summary.json\"\n",
    "best_auto_run.download_file(\n",
    "    \"outputs/featurization_summary.json\", featurization_file_name\n",
    ")\n",
    "\n",
    "# Render the JSON as a pandas DataFrame\n",
    "with open(featurization_file_name, \"r\") as f:\n",
    "    records = json.load(f)\n",
    "\n",
    "#print(records)\n",
    "records_pd = pd.DataFrame.from_records(records)\n",
    "records_pd.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Best Model's explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the best model explanation run to complete\n",
    "\n",
    "model_explainability_run_id = auto_run.id + \"_\" + \"ModelExplain\"\n",
    "print(model_explainability_run_id)\n",
    "model_explainability_run = Run(\n",
    "    experiment=experiment, run_id=model_explainability_run_id\n",
    ")\n",
    "model_explainability_run.wait_for_completion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ExplanationClient.from_run(best_auto_run)\n",
    "engineered_explanations = client.download_model_explanation(raw=False)\n",
    "exp_data = engineered_explanations.get_feature_importance_dict()\n",
    "exp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and save the Best ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
    "\n",
    "bestrun, onnx_mdl = auto_run.get_output(return_onnx_model=True)\n",
    "\n",
    "onnx_fl_path = output_dir+\"/best_model.onnx\"\n",
    "OnnxConverter.save_onnx_model(onnx_mdl, onnx_fl_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690679713518
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_name = best_auto_run.properties[\"model_name\"]\n",
    "print(model_name)\n",
    "description = \"AutoML Model trained on Airbnb boston to predict fraud listing\"\n",
    "tags = None\n",
    "registered_model = auto_run.register_model(\n",
    "    model_name=model_name, description=description, tags=tags\n",
    ")\n",
    "\n",
    "print(\n",
    "    auto_run.model_id\n",
    ") \n",
    "\n",
    "print(\"registered model: \",registered_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690679826332
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_file = src_dir + \"/test.csv\";\n",
    "df_test = pd.read_csv(test_file)\n",
    "df_test = df_test[pd.notnull(df_test['fraud'])]\n",
    "\n",
    "y_test = df_test['fraud']\n",
    "X_test = df_test.drop(['fraud'], axis=1)\n",
    "\n",
    "ypred = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, ypred)\n",
    "\n",
    "pd.DataFrame(cm).style.background_gradient(cmap='Blues', low=0, high=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with ONNX model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import json\n",
    "from azureml.automl.core.onnx_convert import OnnxConvertConstants\n",
    "from azureml.train.automl import constants\n",
    "from azureml.automl.runtime.onnx_convert import OnnxInferenceHelper\n",
    "\n",
    "print(constants.MODEL_RESOURCE_PATH_ONNX)\n",
    "\n",
    "def get_onnx_res(run):\n",
    "    res_path = output_dir + \"/onnx_resource.json\"\n",
    "    run.download_file(\n",
    "        name=constants.MODEL_RESOURCE_PATH_ONNX, output_file_path=res_path\n",
    "    )\n",
    "    with open(res_path) as f:\n",
    "        result = json.load(f)\n",
    "    return result\n",
    "\n",
    "\n",
    "if sys.version_info < OnnxConvertConstants.OnnxIncompatiblePythonVersion:\n",
    "    # test_df = test_dataset.to_pandas_dataframe()\n",
    "    mdl_bytes = onnx_mdl.SerializeToString()\n",
    "    onnx_result = get_onnx_res(best_run)\n",
    "\n",
    "    onnxrt_helper = OnnxInferenceHelper(mdl_bytes, onnx_result)\n",
    "    pred_onnx, pred_prob_onnx = onnxrt_helper.predict(X_test)\n",
    "\n",
    "    print(pred_onnx)\n",
    "    print(pred_prob_onnx)\n",
    "else:\n",
    "    print(\"Please use Python version 3.6 or 3.7 to run the inference helper.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690681280723
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    environment=best_auto_run.get_environment(), entry_script=script_file_name\n",
    ")\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=2,\n",
    "    memory_gb=2,\n",
    "    tags={\"area\": \"bmData\", \"type\": \"automl_classification\"},\n",
    "    description=\"sample service for Automl Classification\",\n",
    ")\n",
    "\n",
    "aci_service_name = model_name.lower()\n",
    "print(aci_service_name)\n",
    "aci_service = Model.deploy(ws, aci_service_name, [registered_model], inference_config, aciconfig)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.scoring_uri)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the logs of the web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690682083586
    }
   },
   "outputs": [],
   "source": [
    "aci_service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Send a request to the web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1690683014092
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import requests\n",
    "# import json\n",
    "\n",
    "X_test_json = X_test.to_json(orient=\"records\")\n",
    "#data = '{\"data\": ' + X_test_json + \"}\"\n",
    "data = '{\"data\": ' + X_test_json + ', \"method\": \"predict\"}'\n",
    "#print(\"test data:\", data)\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "resp = requests.post(aci_service.scoring_uri, data, headers=headers)\n",
    "\n",
    "y_pred = json.loads(json.loads(resp.text))[\"result\"]\n",
    "#print(y_pred)\n",
    "\n",
    "#print(y_test)\n",
    "actual = array(y_test)\n",
    "#actual = actual[:, 0]\n",
    "print(len(y_pred), \" \", len(actual))\n",
    "#print(actual)\n",
    "\n",
    "cm = confusion_matrix(actual, ypred)\n",
    "\n",
    "pd.DataFrame(cm).style.background_gradient(cmap='Blues', low=0, high=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service.delete()\n",
    "\n",
    "compute_target.delete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission Checklist**\n",
    "- I have registered the model.\n",
    "- I have deployed the model with the best accuracy as a webservice.\n",
    "- I have tested the webservice by sending a request to the model endpoint.\n",
    "- I have deleted the webservice and shutdown all the computes that I have used.\n",
    "- I have taken a screenshot showing the model endpoint as active.\n",
    "- The project includes a file containing the environment details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
