{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1598423888013
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "import os\n",
    "import shutil\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "\"Airbnb for Boston with fraud detcetion\" data was downloaded from Kaggle with the following link:\n",
    "\n",
    "https://www.kaggle.com/datasets/hawkingcr/airbnb-for-boston-with-fraud-detection/download?datasetVersionNumber=1\n",
    "\n",
    "The downloaded file is saved as \"output.csv\" in the \"data\" directory. The dataset aims to classify whether an Airbnb listing is a fraud or not.\n",
    "\n",
    "A notebook file named \"data_process.ipyng\" was created to perform some pre-processing on the data. Firstly, a correlation analysis was conducted with the target column \"fraud\" to identify and remove some non-significant features. Next, the data was split into \"train.csv\" and \"test.csv\" sets, and the balance of the training data was examined. Due to the class imbalance in the training target, an upsampling technique was applied to address this imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1598423890461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data path: ./tmp_dir/train.csv\n",
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Uploading file to airbnb_boston\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./tmp_dir/train.csv\n",
      "Uploaded ./tmp_dir/train.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Creating new dataset\n",
      "datastore train data path:  airbnb_boston/train.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>is_location_exact</th>\n",
       "      <th>property_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6500</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9000</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11500</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>27500</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_response_rate  host_identity_verified  host_total_listings_count  \\\n",
       "0                  95                       1                          3   \n",
       "1                 100                       1                          1   \n",
       "2                 100                       1                          1   \n",
       "3                  90                       1                          1   \n",
       "4                  92                       0                          8   \n",
       "\n",
       "   is_location_exact  property_type  accommodates  price  minimum_nights  \\\n",
       "0                  1              8             2   6500               2   \n",
       "1                  1              0             8  50000               1   \n",
       "2                  1              8             2   9000               1   \n",
       "3                  1              0             2  11500               1   \n",
       "4                  1              2             6  27500               2   \n",
       "\n",
       "   number_of_reviews  review_scores_rating  instant_bookable  \\\n",
       "0                  8                  93.0                 0   \n",
       "1                 88                  98.0                 0   \n",
       "2                192                  95.0                 0   \n",
       "3                 54                  88.0                 1   \n",
       "4                 29                  91.0                 1   \n",
       "\n",
       "   cancellation_policy  reviews_per_month  fraud  \n",
       "0                    1               0.63      1  \n",
       "1                    1               4.20      1  \n",
       "2                    1               5.58      1  \n",
       "3                    2               3.58      1  \n",
       "4                    2               0.72      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "experiment_name = 'udacity-aml-capstone'\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "train_data_file = \"train.csv\"\n",
    "src_dir = \"./data\"\n",
    "target_path = \"airbnb_boston\"\n",
    "\n",
    "train_data_dir = \"./tmp_dir\"\n",
    "if os.path.exists(train_data_dir) == False:\n",
    "    os.mkdir(train_data_dir)\n",
    "\n",
    "src_file_path = os.path.join(src_dir,train_data_file)\n",
    "#print(src_file_path)\n",
    "dest = shutil.copy(src_file_path,train_data_dir)\n",
    "#print(\"After copying:\")\n",
    "#print(os.listdir(train_data_dir))\n",
    "print(\"train data path:\",dest)\n",
    "\n",
    "#datastore.upload(\n",
    "    #src_dir=train_data_dir, target_path=target_path, overwrite=True, show_progress=True\n",
    "#)\n",
    "\n",
    "#datastore.upload_files(\n",
    "    #[\"./data/train.csv\"],target_path=\"airbnb_boston\", overwrite=True, show_progress=True\n",
    "#)\n",
    "\n",
    "#Dataset.File.upload_directory(src_dir,(datastore,target_path),pattern=train_data_file,\n",
    "                              #overwrite=True, show_progress=True)\n",
    "Dataset.File.upload_directory(train_data_dir,(datastore,target_path),\n",
    "                              overwrite=True, show_progress=True)\n",
    "\n",
    "# Upload the training data as a tabular dataset for access during training on remote compute\n",
    "datastore_path = os.path.join(target_path,train_data_file)\n",
    "print(\"datastore train data path: \",datastore_path)\n",
    "train_ds = Dataset.Tabular.from_delimited_files(\n",
    "    path=datastore.path(datastore_path)\n",
    ")\n",
    "\n",
    "train_ds.to_pandas_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Attach an AmlCompute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_name = \"my-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print(\"Found existing cluster, use it.\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"STANDARD_D2_V2\", max_nodes=4\n",
    "    )\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "compute_target.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "TODO: Explain why you chose the automl settings and cofiguration you used below.\n",
    "\n",
    "iteration_timeout_minutes: Time limit in minutes for each iteration. Increase this value for larger datasets that need more time for each iteration.\n",
    "\n",
    "experiment_timeout_hours: Maximum amount of time in hours that all iterations combined can take before the experiment terminates.\n",
    "\n",
    "enable_early_stopping: Flag to enable early termination if the score is not improving in the short term.\n",
    "\n",
    "primary_metric: Metric that you want to optimize. The best-fit model will be chosen based on this metric.\n",
    "\n",
    "featurization: By using auto, the experiment can preprocess the input data (handling missing data, converting text to numeric, etc.)\n",
    "\n",
    "verbosity: Controls the level of logging.\n",
    "\n",
    "n_cross_validation: Number of cross validation to perform when validation data is\n",
    "                    not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\": 10,\n",
    "    \"experiment_timeout_minutes\": 30,\n",
    "    \"max_concurrent_iterations\": 4,\n",
    "    \"enable_early_stopping\": True,\n",
    "    \"primary_metric\": 'AUC_weighted',\n",
    "    \"featurization\": 'auto',\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"n_cross_validations\": 5\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(\n",
    "    task=\"classification\",\n",
    "    compute_target=compute_target,\n",
    "    training_data=train_ds,\n",
    "    label_column_name=\"fraud\",\n",
    "    blocked_models=[\"KNN\", \"LinearSVM\"],\n",
    "    enable_onnx_compatible_models=True,\n",
    "    **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit experiment\n",
    "auto_run = experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(auto_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve and save best automl model.\n",
    "\n",
    "auto_run.wait_for_completion(show_output=True)\n",
    "assert(auto_run.get_status() == \"Completed\")\n",
    "\n",
    "# Note two ways to get best_run, compare them (?)\n",
    "best_auto_run, best_model = auto_run.get_output()\n",
    "# best_auto_child = auto_run.get_best_child()\n",
    "\n",
    "print(best_auto_run.get_details())\n",
    "#print(best_auto_child.get_details())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to get best run\n",
    "\n",
    "best_auto_child = auto_run.get_best_child()\n",
    "print(best_auto_child.get_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download some outputs\n",
    "output_dir = \"./outputs\"\n",
    "if os.path.exists(output_dir) == False:\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "script_file_name = output_dir + \"/score.py\"\n",
    "best_auto_run.download_file(\"outputs/scoring_file_v_1_0_0.py\", script_file_name)\n",
    "\n",
    "# Download the featurization summary JSON file locally\n",
    "featurization_file_name = output_dir + \"/featurization_summary.json\"\n",
    "best_auto_run.download_file(\n",
    "    \"outputs/featurization_summary.json\", featurization_file_name\n",
    ")\n",
    "\n",
    "# Render the JSON as a pandas DataFrame\n",
    "with open(featurization_file_name, \"r\") as f:\n",
    "    records = json.load(f)\n",
    "\n",
    "print(records)\n",
    "records_pd = pd.DataFrame.from_records(records)\n",
    "records_pd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "import joblib\n",
    "\n",
    "best_model_file = output_dir + \"/best_model.pkl\"\n",
    "#print(best_model)\n",
    "joblib.dump(best_model,best_model_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "autorun_model = Model.register(model_path=best_model_file,\n",
    "                            model_name=\"autorun_model\",\n",
    "                            workspace=ws)\n",
    "\n",
    "autorun_model_path = Model.get_model_path(model_name='autorun_model',_workspace=ws)\n",
    "print(\"registered best model path: \",autorun_model_path)\n",
    "\n",
    "# read back model to test\n",
    "saved_model = joblib.load(autorun_model_path)\n",
    "# registered_model = joblib.load(best_model_file)\n",
    "\n",
    "print(\"saved model:\",saved_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way of register model\n",
    "\n",
    "model_name = best_auto_run.properties[\"model_name\"]\n",
    "print(model_name)\n",
    "description = \"AutoML Model trained on Airbnb boston to predict fraud listing\"\n",
    "tags = None\n",
    "registered_model = auto_run.register_model(\n",
    "    model_name=model_name, description=description, tags=tags\n",
    ")\n",
    "\n",
    "print(\n",
    "    auto_run.model_id\n",
    ")  # This will be written to the script file later in the notebook.\n",
    "print(\"registered model: \",registered_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_file = src_dir + \"/test.csv\";\n",
    "df_test = pd.read_csv(test_file)\n",
    "df_test = df_test[pd.notnull(df_test['y'])]\n",
    "\n",
    "y_test = df_test['y']\n",
    "X_test = df_test.drop(['y'], axis=1)\n",
    "\n",
    "ypred = best_model.predict(X_test)\n",
    "#ypred = saved_model.predict(X_test)\n",
    "#ypred = registered_model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, ypred)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "pd.DataFrame(cm).style.background_gradient(cmap='Blues', low=0, high=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy Webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    environment=best_auto_run.get_environment(), entry_script=script_file_name\n",
    ")\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=2,\n",
    "    memory_gb=2,\n",
    "    tags={\"area\": \"bmData\", \"type\": \"automl_classification\"},\n",
    "    description=\"sample service for Automl Classification\",\n",
    ")\n",
    "\n",
    "aci_service_name = model_name.lower()\n",
    "print(aci_service_name)\n",
    "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import requests\n",
    "import json\n",
    "\n",
    "X_test_json = X_test.to_json(orient=\"records\")\n",
    "data = '{\"data\": ' + X_test_json + \"}\"\n",
    "print(\"test data:\", data)\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "resp = requests.post(aci_service.scoring_uri, data, headers=headers)\n",
    "\n",
    "y_pred = json.loads(json.loads(resp.text))[\"result\"]\n",
    "\n",
    "actual = array(y_test)\n",
    "actual = actual[:, 0]\n",
    "print(len(y_pred), \" \", len(actual))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission Checklist**\n",
    "- I have registered the model.\n",
    "- I have deployed the model with the best accuracy as a webservice.\n",
    "- I have tested the webservice by sending a request to the model endpoint.\n",
    "- I have deleted the webservice and shutdown all the computes that I have used.\n",
    "- I have taken a screenshot showing the model endpoint as active.\n",
    "- The project includes a file containing the environment details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
