{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1691244711507
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice, uniform\n",
    "from azureml.core import Environment, ScriptRunConfig\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "\"Airbnb for Boston with fraud detcetion\" data was downloaded from Kaggle with the following link:\n",
    "\n",
    "https://www.kaggle.com/datasets/hawkingcr/airbnb-for-boston-with-fraud-detection/download?datasetVersionNumber=1\n",
    "\n",
    "The downloaded file was saved as \"output.csv\" in the \"data\" directory. The dataset aims to classify whether an Airbnb listing is a fraud or not.\n",
    "\n",
    "A notebook file named \"data_process.ipyng\" was created to perform some pre-processing on the data. Firstly, a correlation analysis was conducted with the target column \"fraud\" to identify and remove some non-significant features. Next, the data was split into \"train.csv\" and \"test.csv\" sets, and the balance of the training data was examined. Due to the class imbalance in the training target, an upsampling technique was applied to address this imbalance.\n",
    "\n",
    "A script file named \"data_set.py\" was created in the scripts directory. Two functions getTrainingDataset() and getTestDataset() are defined to register traing and test data as dataset in the workspace.\n",
    "\n",
    "### Get Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1691244725097
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from scripts.data_set import getTrainingDataset, getTestDataset\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "experiment_name = 'udacity-aml-capstone-hyperparameter'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "train_ds = getTrainingDataset(ws)\n",
    "test_ds = getTestDataset(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.to_pandas_dataframe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds.to_pandas_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Attach an AmlCompute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1691244734253
    }
   },
   "outputs": [],
   "source": [
    "cluster_name = \"my-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print(\"Found existing cluster, use it.\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"STANDARD_D2_V2\", max_nodes=4\n",
    "    )\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Hyperdrive Configuration\n",
    "\n",
    "Logistic Regression model is employed here. I picked four tuning parameters. Two are related to regularization, i.e. inverse of regularization strength and penalty term. \n",
    "Two are related to optimization, i.e. solver for optimization method and max number of iterations for solver to converge.\n",
    "\n",
    "To tune parameters, I picked Random sampling method to handle both continuous and discrete parameters efficiently.\n",
    "\n",
    "For early termination policy, agressive BanditPolicy is chosen with a small slack_factor of 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1691249035850
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Early termination policy. \n",
    "early_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
    "\n",
    "# Tuning parameters\n",
    "param_sampling = RandomParameterSampling(\n",
    "    {\n",
    "        '--C': uniform(0.5,1.5),\n",
    "        '--max_iter': choice(75, 100, 125),\n",
    "        '--penalty': choice('l1','l2'),\n",
    "        '--solver': choice('lbfgs','liblinear','newton-cg',\n",
    "                           'newton-cholesky','sag','saga')\n",
    "    }\n",
    ")\n",
    "\n",
    "#if \"scripts\" not in os.listdir():\n",
    "#    os.mkdir(\"./scripts\")\n",
    "\n",
    "# Setup environment for your training run\n",
    "sklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='hyperdrive_env.yml')\n",
    "\n",
    "estimator = ScriptRunConfig(source_directory='./scripts',\n",
    "                      script='logistic_regression.py',\n",
    "                      compute_target=compute_target,\n",
    "                      environment=sklearn_env)\n",
    "\n",
    "# Create a HyperDriveConfig using the src object, hyperparameter sampler, and policy.\n",
    "hyperdrive_run_config = HyperDriveConfig(run_config=estimator,\n",
    "                                     hyperparameter_sampling=param_sampling,\n",
    "                                     policy=early_termination_policy,\n",
    "                                     primary_metric_name='Accuracy',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs=20,\n",
    "                                     max_concurrent_runs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1691249043280
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "hyperdrive_run = experiment.submit(config=hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598544898497
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Run Details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1691249052825
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1691249698142
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Get best run\n",
    "\n",
    "hyperdrive_run.wait_for_completion(show_output=True)\n",
    "assert(hyperdrive_run.get_status() == \"Completed\")\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1691250102996
    }
   },
   "outputs": [],
   "source": [
    "# show best run\n",
    "\n",
    "print(\"best metrics: \",best_run.get_metrics())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run.get_file_names())\n",
    "# print(\"run env: \",best_run.get_environment())\n",
    "# print(best_run.get_details())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1691250118283
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "output_dir = \"./outputs\"\n",
    "if os.path.exists(output_dir) == False:\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "# download and save best model\n",
    "\n",
    "best_model_name = output_dir + \"/best_hyperdrive_model.pkl\"\n",
    "best_run.download_file(\"outputs/model/model.pkl\",best_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1691250140096
    }
   },
   "outputs": [],
   "source": [
    "best_model = joblib.load(best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1691250165476
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(best_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1691250196621
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "src_dir = \"./data\"\n",
    "test_file = src_dir + \"/test.csv\";\n",
    "df_test = pd.read_csv(test_file)\n",
    "df_test = df_test[pd.notnull(df_test['fraud'])]\n",
    "\n",
    "y_test = df_test['fraud']\n",
    "X_test = df_test.drop(['fraud'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1691250204895
    }
   },
   "outputs": [],
   "source": [
    "ypred = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, ypred)\n",
    "\n",
    "pd.DataFrame(cm).style.background_gradient(cmap='Blues', low=0, high=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Model Registration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1691250445939
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"airbnb-boston-hyperparameter\"\n",
    "\n",
    "description = \"logistic_regression model to predict airbnb fraud listing\"\n",
    "\n",
    "registered_model = best_run.register_model(model_name=model_name,\n",
    "                        model_path=\"outputs/model\",description=description)\n",
    "\n",
    "print(\"registered model: \",registered_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model in ACI\n",
    "\n",
    "First we created \"score.py\" under scripts directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%writefile scripts/score.py\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "import azureml.automl.core\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model/model.pkl')\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Loading model from path.\")\n",
    "        model = joblib.load(model_path)\n",
    "        logging.info(\"Loading successful.\")\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Exception on load model\")\n",
    "        raise\n",
    "\n",
    "def run(data, method=\"predict\"):\n",
    "    try:\n",
    "        if method == \"predict_proba\":\n",
    "            result = model.predict_proba(data)\n",
    "        elif method == \"predict\":\n",
    "            result = model.predict(data)\n",
    "        else:\n",
    "            raise Exception(f\"Invalid predict method argument received ({method})\")\n",
    "        if isinstance(result, pd.DataFrame):\n",
    "            result = result.values\n",
    "        return json.dumps({\"result\": result.tolist()})\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create myenv.yml\n",
    "\n",
    "Create an environment file so that Azure Machine Learning can install the necessary packages in the Docker image which are required by your scoring script. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import CondaDependencies\n",
    "\n",
    "cd = CondaDependencies.create()\n",
    "cd.add_conda_package('numpy')\n",
    "cd.add_conda_package('pandas')\n",
    "cd.add_pip_package('scikit-learn')\n",
    "cd.add_pip_package(\"azureml-defaults\")\n",
    "# cd.add_pip_package(\"protobuf==3.20.1\")\n",
    "cd.save_to_file(base_directory='./', conda_file_path='myenv.yml')\n",
    "\n",
    "print(cd.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to ACI\n",
    "\n",
    "Create the inference configuration and deployment configuration and deploy to ACI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.model import Model\n",
    "\n",
    "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"myenv.yml\")\n",
    "inference_config = InferenceConfig(entry_script=\"scripts/score.py\", environment=myenv)\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=2, \n",
    "                                               memory_gb=2, \n",
    "                                               tags={'name':'logistic_regression'},\n",
    "                                               description='log_reg classification')\n",
    "\n",
    "service = Model.deploy(workspace=ws, \n",
    "                           name='hyperdrive_model', \n",
    "                           models=[registered_model], \n",
    "                           inference_config=inference_config, \n",
    "                           deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
